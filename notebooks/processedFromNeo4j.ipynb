{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ad37d7db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Konfigurasi Selesai.\n",
      "ðŸ“‚ Membaca data dari: /home/ahnaf-al-ghiffarri-ahtasyafi/Documents/programming/neo4j/data/processed/neo4j_nodes.csv\n"
     ]
    }
   ],
   "source": [
    "# Cell 1 - imports & config\n",
    "import os, json, math, random, time\n",
    "import numpy as np, pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.utils import from_networkx\n",
    "import networkx as nx\n",
    "# Pastikan sudah install node2vec: pip install node2vec\n",
    "from node2vec import Node2Vec  \n",
    "import xgboost as xgb\n",
    "\n",
    "# --- UPDATE PATH (PENTING) ---\n",
    "# Menggunakan \"../\" untuk naik satu level dari folder 'notebooks' ke root project\n",
    "NODES_CSV = \"../data/processed/neo4j_nodes.csv\"\n",
    "EDGES_CSV = \"../data/processed/neo4j_edges.csv\"\n",
    "OUT_DIR = \"../data/processed/\"\n",
    "\n",
    "# Buat folder output jika belum ada\n",
    "os.makedirs(OUT_DIR, exist_ok=True)\n",
    "\n",
    "# reproducibility (Agar hasil konsisten)\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "\n",
    "print(f\"âœ… Konfigurasi Selesai.\")\n",
    "print(f\"ðŸ“‚ Membaca data dari: {os.path.abspath(NODES_CSV)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6c51b4d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nodes: (1879, 13)\n",
      "edges: (6000, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>node_id</th>\n",
       "      <th>label</th>\n",
       "      <th>community_id</th>\n",
       "      <th>community_size</th>\n",
       "      <th>community_density</th>\n",
       "      <th>degree</th>\n",
       "      <th>pagerank</th>\n",
       "      <th>betweenness</th>\n",
       "      <th>closeness</th>\n",
       "      <th>tarif_seharusnya</th>\n",
       "      <th>tarif_diklaim</th>\n",
       "      <th>lama_rawat</th>\n",
       "      <th>fraud_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Patient</td>\n",
       "      <td>1579</td>\n",
       "      <td>65</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>0.640479</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Claim</td>\n",
       "      <td>1579</td>\n",
       "      <td>65</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>0.724720</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3142869.0</td>\n",
       "      <td>3293000.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Diagnosis</td>\n",
       "      <td>1579</td>\n",
       "      <td>65</td>\n",
       "      <td>NaN</td>\n",
       "      <td>62</td>\n",
       "      <td>8.130346</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Procedure</td>\n",
       "      <td>1579</td>\n",
       "      <td>65</td>\n",
       "      <td>NaN</td>\n",
       "      <td>95</td>\n",
       "      <td>12.453211</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>ServiceType</td>\n",
       "      <td>33</td>\n",
       "      <td>321</td>\n",
       "      <td>NaN</td>\n",
       "      <td>562</td>\n",
       "      <td>73.233768</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   node_id        label  community_id  community_size  community_density  \\\n",
       "0        0      Patient          1579              65                NaN   \n",
       "1        1        Claim          1579              65                NaN   \n",
       "2        2    Diagnosis          1579              65                NaN   \n",
       "3        3    Procedure          1579              65                NaN   \n",
       "4        4  ServiceType            33             321                NaN   \n",
       "\n",
       "   degree   pagerank  betweenness  closeness  tarif_seharusnya  tarif_diklaim  \\\n",
       "0       4   0.640479          NaN        NaN               NaN            NaN   \n",
       "1       5   0.724720          NaN        NaN         3142869.0      3293000.0   \n",
       "2      62   8.130346          NaN        NaN               NaN            NaN   \n",
       "3      95  12.453211          NaN        NaN               NaN            NaN   \n",
       "4     562  73.233768          NaN        NaN               NaN            NaN   \n",
       "\n",
       "   lama_rawat  fraud_label  \n",
       "0         NaN          NaN  \n",
       "1         3.0          1.0  \n",
       "2         NaN          NaN  \n",
       "3         NaN          NaN  \n",
       "4         NaN          NaN  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cell 2 - load\n",
    "nodes = pd.read_csv(NODES_CSV)\n",
    "edges = pd.read_csv(EDGES_CSV)\n",
    "\n",
    "print(\"nodes:\", nodes.shape)\n",
    "print(\"edges:\", edges.shape)\n",
    "nodes.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e354144c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mapped nodes: 1879 mapped edges: 6000\n"
     ]
    }
   ],
   "source": [
    "# Cell 3 - ensure mapped_id index used for PyG mapping\n",
    "# If file already has mapped_id column, use it; else create mapped from node_id order\n",
    "if 'mapped_id' not in nodes.columns:\n",
    "    nodes = nodes.sort_values('node_id').reset_index(drop=True)\n",
    "    nodes['mapped_id'] = np.arange(len(nodes))\n",
    "else:\n",
    "    nodes['mapped_id'] = nodes['mapped_id'].astype(int)\n",
    "\n",
    "# Map original node_id -> mapped_id\n",
    "nid_to_mid = dict(zip(nodes['node_id'].astype(int), nodes['mapped_id'].astype(int)))\n",
    "# apply mapping for edges\n",
    "edges['source_mapped'] = edges['source'].astype(int).map(nid_to_mid)\n",
    "edges['target_mapped'] = edges['target'].astype(int).map(nid_to_mid)\n",
    "# drop edges with missing mapping\n",
    "edges = edges.dropna(subset=['source_mapped','target_mapped']).astype({'source_mapped':int,'target_mapped':int})\n",
    "print(\"mapped nodes:\", nodes['mapped_id'].nunique(), \"mapped edges:\", len(edges))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "80de5175",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "categorical cols found: []\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ratio_tarif</th>\n",
       "      <td>1879.0</td>\n",
       "      <td>0.754894</td>\n",
       "      <td>6.655472e-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.983269</td>\n",
       "      <td>1.023709</td>\n",
       "      <td>3.940295e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>delta_tarif</th>\n",
       "      <td>1879.0</td>\n",
       "      <td>366665.970729</td>\n",
       "      <td>1.720173e+06</td>\n",
       "      <td>-665147.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>25206.500000</td>\n",
       "      <td>2.565066e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lama_rawat</th>\n",
       "      <td>1879.0</td>\n",
       "      <td>1.257052</td>\n",
       "      <td>1.640613e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.100000e+01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              count           mean           std       min  25%       50%  \\\n",
       "ratio_tarif  1879.0       0.754894  6.655472e-01       0.0  0.0  0.983269   \n",
       "delta_tarif  1879.0  366665.970729  1.720173e+06 -665147.0  0.0  0.000000   \n",
       "lama_rawat   1879.0       1.257052  1.640613e+00       0.0  0.0  1.000000   \n",
       "\n",
       "                      75%           max  \n",
       "ratio_tarif      1.023709  3.940295e+00  \n",
       "delta_tarif  25206.500000  2.565066e+07  \n",
       "lama_rawat       1.000000  1.100000e+01  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cell 4 - basic features\n",
    "nodes['tarif_seharusnya'] = pd.to_numeric(nodes.get('tarif_seharusnya',0), errors='coerce').fillna(0)\n",
    "nodes['tarif_diklaim'] = pd.to_numeric(nodes.get('tarif_diklaim',0), errors='coerce').fillna(0)\n",
    "nodes['lama_rawat'] = pd.to_numeric(nodes.get('lama_rawat',0), errors='coerce').fillna(0)\n",
    "\n",
    "# ratio & delta\n",
    "nodes['ratio_tarif'] = nodes['tarif_diklaim'] / (nodes['tarif_seharusnya'].replace(0, np.nan))\n",
    "nodes['ratio_tarif'] = nodes['ratio_tarif'].fillna(0)\n",
    "nodes['delta_tarif'] = nodes['tarif_diklaim'] - nodes['tarif_seharusnya']\n",
    "\n",
    "# categorical features: example 'kelas_rawat' or 'jenis_pelayanan' maybe in columns\n",
    "cat_cols = []\n",
    "for c in ['kelas_rawat','jenis_pelayanan','diagnosis_utama','prosedur']:\n",
    "    if c in nodes.columns:\n",
    "        cat_cols.append(c)\n",
    "\n",
    "print(\"categorical cols found:\", cat_cols)\n",
    "nodes[['ratio_tarif','delta_tarif','lama_rawat']].describe().T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2fe6d382",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ Warning: Kolom 'is_fraud' tidak ditemukan. Membuat dummy label (0).\n",
      "âœ… Total node yang dianggap 'Claim': 1200\n",
      "âš ï¸ Stratify dinonaktifkan (Hanya ada 1 jenis label di data).\n",
      "------------------------------\n",
      "âœ… Split Selesai.\n",
      "ðŸ“Š Train set: 840 claims\n",
      "ðŸ“Š Test set : 360 claims\n"
     ]
    }
   ],
   "source": [
    "# Cell 5 - split (Fixed Version)\n",
    "\n",
    "# 1. HANDLING LABEL FRAUD (Perbaikan Error 'int' object)\n",
    "# Cek dulu apakah kolom 'is_fraud' benar-benar ada di CSV\n",
    "if 'is_fraud' in nodes.columns:\n",
    "    # Jika ada, isi nilai kosong dengan 0, lalu jadikan integer\n",
    "    nodes['is_fraud'] = nodes['is_fraud'].fillna(0).astype(int)\n",
    "else:\n",
    "    # Jika TIDAK ada, kita buat kolom dummy isinya 0 semua (dianggap aman/tidak fraud)\n",
    "    print(\"âš ï¸ Warning: Kolom 'is_fraud' tidak ditemukan. Membuat dummy label (0).\")\n",
    "    nodes['is_fraud'] = 0\n",
    "\n",
    "# 2. IDENTIFIKASI NODE CLAIM\n",
    "# Kita hanya ingin membagi dataset berdasarkan node 'Claim', bukan Dokter atau RS.\n",
    "if 'label' in nodes.columns:\n",
    "    is_claim = nodes['label'].astype(str) == 'Claim'\n",
    "else:\n",
    "    # Fallback logic: Jika ID node diawali huruf 'C' (misal C001), itu Claim.\n",
    "    # Sesuaikan ini dengan format ID di CSV kamu.\n",
    "    # Jika ragu, kita anggap semua node yang punya 'tarif_diklaim' > 0 adalah Claim\n",
    "    is_claim = nodes['tarif_diklaim'] > 0 \n",
    "    \n",
    "    # Jika masih kosong juga, ambil semua node (opsi terakhir)\n",
    "    if is_claim.sum() == 0:\n",
    "        print(\"âš ï¸ Warning: Tidak bisa mendeteksi node Claim spesifik. Menggunakan semua node.\")\n",
    "        is_claim = pd.Series([True] * len(nodes))\n",
    "\n",
    "claim_nodes = nodes[is_claim].copy()\n",
    "print(f\"âœ… Total node yang dianggap 'Claim': {len(claim_nodes)}\")\n",
    "\n",
    "# 3. LOGIC STRATIFY (Pencegahan Error Single Class)\n",
    "# Stratify akan error jika semua datanya 0 (tidak ada fraud).\n",
    "unique_labels = claim_nodes['is_fraud'].unique()\n",
    "if len(unique_labels) > 1:\n",
    "    stratify_col = claim_nodes['is_fraud']\n",
    "    print(\"â„¹ï¸ Stratify aktif (Data memiliki label 0 dan 1).\")\n",
    "else:\n",
    "    stratify_col = None\n",
    "    print(\"âš ï¸ Stratify dinonaktifkan (Hanya ada 1 jenis label di data).\")\n",
    "\n",
    "# 4. LAKUKAN SPLIT\n",
    "train_claim, test_claim = train_test_split(\n",
    "    claim_nodes,\n",
    "    test_size=0.3,\n",
    "    stratify=stratify_col, # Gunakan logic aman di atas\n",
    "    random_state=SEED\n",
    ")\n",
    "\n",
    "# 5. BUAT MASK (PENTING UNTUK GNN)\n",
    "# Kita menandai node mana yang masuk training set dan test set langsung di tabel utama\n",
    "train_mids = set(train_claim['mapped_id'].tolist())\n",
    "test_mids = set(test_claim['mapped_id'].tolist())\n",
    "\n",
    "nodes['train_mask'] = nodes['mapped_id'].apply(lambda x: x in train_mids)\n",
    "nodes['test_mask']  = nodes['mapped_id'].apply(lambda x: x in test_mids)\n",
    "\n",
    "# 6. SIMPAN CONFIG\n",
    "split_meta = {\n",
    "    'seed': SEED,\n",
    "    'train_count': len(train_claim),\n",
    "    'test_count': len(test_claim),\n",
    "    'has_fraud_label': len(unique_labels) > 1,\n",
    "    'timestamp': time.strftime(\"%Y%m%d_%H%M%S\")\n",
    "}\n",
    "\n",
    "with open(os.path.join(OUT_DIR, \"split_config.json\"), \"w\") as f:\n",
    "    json.dump(split_meta, f, indent=2)\n",
    "\n",
    "print(\"-\" * 30)\n",
    "print(f\"âœ… Split Selesai.\")\n",
    "print(f\"ðŸ“Š Train set: {len(train_claim)} claims\")\n",
    "print(f\"ðŸ“Š Test set : {len(test_claim)} claims\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "75229614",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 6 - train-only aggregates\n",
    "# Example: community_train_fraud_rate and community_size (if community exists)\n",
    "if 'community' in nodes.columns:\n",
    "    # compute using train nodes only\n",
    "    train_df = nodes[nodes['train_mask']]\n",
    "    comm_stats = train_df.groupby('community').agg(\n",
    "        community_train_fraud_rate = ('is_fraud','mean'),\n",
    "        community_train_count = ('is_fraud','count')\n",
    "    ).reset_index().rename(columns={'community':'community'})\n",
    "    # merge to nodes; fillna 0\n",
    "    nodes = nodes.merge(comm_stats, on='community', how='left')\n",
    "    nodes['community_train_fraud_rate'] = nodes['community_train_fraud_rate'].fillna(0)\n",
    "    nodes['community_train_count'] = nodes['community_train_count'].fillna(0)\n",
    "else:\n",
    "    nodes['community_train_fraud_rate'] = 0.0\n",
    "    nodes['community_train_count'] = 0\n",
    "\n",
    "# provider example: if provider id exists (skip if not)\n",
    "if 'provider_id' in nodes.columns:\n",
    "    train_df = nodes[nodes['train_mask']]\n",
    "    prov_stats = train_df.groupby('provider_id').agg(\n",
    "        provider_train_fraud_rate=('is_fraud','mean'),\n",
    "        provider_train_count=('is_fraud','count')\n",
    "    ).reset_index()\n",
    "    nodes = nodes.merge(prov_stats, on='provider_id', how='left')\n",
    "    nodes['provider_train_fraud_rate'] = nodes['provider_train_fraud_rate'].fillna(0)\n",
    "    nodes['provider_train_count'] = nodes['provider_train_count'].fillna(0)\n",
    "else:\n",
    "    nodes['provider_train_fraud_rate'] = 0.0\n",
    "    nodes['provider_train_count'] = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "73f0f311",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing transition probabilities: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1879/1879 [00:01<00:00, 1032.27it/s]\n",
      "Generating walks (CPU: 1): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:12<00:00,  2.06it/s]\n",
      "Generating walks (CPU: 3): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:11<00:00,  2.09it/s]\n",
      "Generating walks (CPU: 2): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:12<00:00,  2.05it/s]\n",
      "Generating walks (CPU: 4): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:12<00:00,  2.05it/s]\n"
     ]
    }
   ],
   "source": [
    "# Cell 7 - build networkx and compute structural features if missing\n",
    "G = nx.Graph()\n",
    "G.add_nodes_from(nodes['mapped_id'].tolist())\n",
    "G.add_edges_from(edges[['source_mapped','target_mapped']].values.tolist())\n",
    "\n",
    "# degree (ensure)\n",
    "deg = dict(G.degree())\n",
    "nodes['degree'] = nodes['mapped_id'].map(deg).fillna(0).astype(int)\n",
    "\n",
    "# pagerank (if not present)\n",
    "if 'pagerank' not in nodes.columns or nodes['pagerank'].isnull().all():\n",
    "    pr = nx.pagerank(G, alpha=0.85)\n",
    "    nodes['pagerank'] = nodes['mapped_id'].map(pr).fillna(0)\n",
    "\n",
    "# Node2Vec embeddings\n",
    "node2vec = Node2Vec(G, dimensions=64, walk_length=30, num_walks=100, workers=4, seed=SEED)\n",
    "n2v_model = node2vec.fit(window=10, min_count=1, batch_words=4)\n",
    "# map embeddings\n",
    "emb_dim = n2v_model.wv.vector_size\n",
    "embs = np.zeros((len(nodes), emb_dim), dtype=np.float32)\n",
    "for mid in nodes['mapped_id']:\n",
    "    try:\n",
    "        embs[mid,:] = n2v_model.wv.get_vector(str(mid))\n",
    "    except Exception:\n",
    "        embs[mid,:] = np.random.normal(0,0.01,emb_dim)\n",
    "# create dataframe\n",
    "emb_df = pd.DataFrame(embs, columns=[f'n2v_{i}' for i in range(emb_dim)])\n",
    "emb_df['mapped_id'] = nodes['mapped_id'].values\n",
    "nodes = nodes.merge(emb_df, on='mapped_id', how='left')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9b396a40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "âœ… Feature Engineering Selesai.\n",
      "ðŸ”¢ Jumlah Fitur Final: 73\n",
      "ðŸ“‹ Daftar Fitur (10 pertama): ['ratio_tarif', 'delta_tarif', 'lama_rawat', 'degree', 'pagerank', 'community_train_fraud_rate', 'community_train_count', 'provider_train_fraud_rate', 'provider_train_count', 'n2v_0']\n"
     ]
    }
   ],
   "source": [
    "# Cell 8 - choose features (FIXED)\n",
    "\n",
    "# numeric features\n",
    "num_feats = ['ratio_tarif','delta_tarif','lama_rawat','degree','pagerank',\n",
    "             'community_train_fraud_rate','community_train_count',\n",
    "             'provider_train_fraud_rate','provider_train_count']\n",
    "\n",
    "# include all node2vec columns (pastikan Cell 7 sudah dijalankan sebelumnya)\n",
    "n2v_cols = [c for c in nodes.columns if c.startswith('n2v_')]\n",
    "num_feats += n2v_cols\n",
    "\n",
    "# categorical encoding (example for service type or care class)\n",
    "cat_cols = [c for c in ['ServiceType','CareClass','jenis_pelayanan','kelas_rawat'] if c in nodes.columns]\n",
    "\n",
    "# --- BAGIAN PERBAIKAN ---\n",
    "# Gunakan 'sparse_output' bukan 'sparse' untuk scikit-learn versi baru\n",
    "ohe = OneHotEncoder(sparse_output=False, handle_unknown='ignore')\n",
    "# ------------------------\n",
    "\n",
    "if len(cat_cols) > 0:\n",
    "    # Isi nilai null dengan 'NA' agar tidak error saat encoding\n",
    "    cat_df = nodes[cat_cols].fillna('NA')\n",
    "    cat_enc = ohe.fit_transform(cat_df)\n",
    "    \n",
    "    # Ambil nama fitur baru\n",
    "    cat_names = []\n",
    "    for i, c in enumerate(cat_cols):\n",
    "        categories = ohe.categories_[i]\n",
    "        cat_names += [f\"{c}__{cat}\" for cat in categories]\n",
    "    \n",
    "    # Buat dataframe hasil encoding\n",
    "    cat_enc_df = pd.DataFrame(cat_enc, columns=cat_names, index=nodes.index)\n",
    "    \n",
    "    # Gabungkan kembali ke nodes utama\n",
    "    # Kita reset index untuk memastikan urutan baris pas saat concat\n",
    "    nodes = pd.concat([nodes.reset_index(drop=True), cat_enc_df.reset_index(drop=True)], axis=1)\n",
    "    cat_feat_cols = cat_names\n",
    "else:\n",
    "    cat_feat_cols = []\n",
    "\n",
    "# final features list\n",
    "FEATURE_COLS = num_feats + cat_feat_cols\n",
    "\n",
    "print(\"-\" * 30)\n",
    "print(\"âœ… Feature Engineering Selesai.\")\n",
    "print(f\"ðŸ”¢ Jumlah Fitur Final: {len(FEATURE_COLS)}\")\n",
    "print(\"ðŸ“‹ Daftar Fitur (10 pertama):\", FEATURE_COLS[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "165a5e7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(x=[1879, 73], edge_index=[2, 6000], y=[1879], num_nodes=1879, train_mask=[1879], test_mask=[1879])\n"
     ]
    }
   ],
   "source": [
    "# Cell 9 - build PyG Data object\n",
    "import torch\n",
    "from torch_geometric.utils import dense_to_sparse\n",
    "\n",
    "# node feature tensor\n",
    "X = torch.tensor(nodes[FEATURE_COLS].fillna(0).values, dtype=torch.float)\n",
    "\n",
    "# labels (binary)\n",
    "y = torch.tensor(nodes['is_fraud'].fillna(0).astype(int).values, dtype=torch.float)\n",
    "\n",
    "# edge_index\n",
    "edge_index = torch.tensor(edges[['source_mapped','target_mapped']].values.T, dtype=torch.long)\n",
    "\n",
    "data = Data(x=X, edge_index=edge_index, y=y)\n",
    "data.num_nodes = X.shape[0]\n",
    "# masks\n",
    "train_mask = torch.tensor(nodes['train_mask'].values, dtype=torch.bool)\n",
    "test_mask  = torch.tensor(nodes['test_mask'].values, dtype=torch.bool)\n",
    "data.train_mask = train_mask\n",
    "data.test_mask = test_mask\n",
    "\n",
    "print(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76273a7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Model HybridGNN berhasil diperbaiki!\n"
     ]
    }
   ],
   "source": [
    "# Cell 10 - model (FIXED)\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GATConv, GCNConv\n",
    "\n",
    "class HybridGNN(nn.Module):\n",
    "    def __init__(self, in_dim, hidden=128, out_dim=1, heads=4, dropout=0.3):\n",
    "        super().__init__()\n",
    "        \n",
    "        # --- PERBAIKAN DISINI ---\n",
    "        # Kita bagi hidden dengan jumlah heads agar total outputnya pas kembali ke 'hidden'\n",
    "        # Contoh: 128 // 4 = 32 per head. Total: 32 * 4 = 128.\n",
    "        gat_out_channels = hidden // heads\n",
    "        \n",
    "        self.gat1 = GATConv(in_dim, gat_out_channels, heads=heads, concat=True)\n",
    "        # Sekarang output GAT adalah (hidden), jadi pas masuk ke GCN (hidden)\n",
    "        self.gcn1 = GCNConv(hidden, hidden)\n",
    "        \n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(hidden, hidden//2),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(hidden//2, out_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        # x shape awal: [N, in_dim]\n",
    "        \n",
    "        x = self.gat1(x, edge_index) \n",
    "        # x shape sekarang: [N, hidden] (karena 32 * 4 heads = 128)\n",
    "        \n",
    "        x = F.elu(x)\n",
    "        x = F.dropout(x, p=0.3, training=self.training) # Tambahkan dropout biar lebih robust\n",
    "        \n",
    "        x = self.gcn1(x, edge_index)\n",
    "        # x shape: [N, hidden]\n",
    "        \n",
    "        x = F.relu(x)\n",
    "        x = self.fc(x)\n",
    "        \n",
    "        return torch.sigmoid(x).view(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "536fb87c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pos_weight: 1039.0\n",
      "Epoch 5 loss=0.0045 AUC=nan PR-AUC=0.0000\n",
      "Epoch 10 loss=0.0024 AUC=nan PR-AUC=0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ahnaf-al-ghiffarri-ahtasyafi/Documents/programming/neo4j/gnn_env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py:424: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.\n",
      "  warnings.warn(\n",
      "/home/ahnaf-al-ghiffarri-ahtasyafi/Documents/programming/neo4j/gnn_env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py:1046: UserWarning: No positive class found in y_true, recall is set to one for all thresholds.\n",
      "  warnings.warn(\n",
      "/home/ahnaf-al-ghiffarri-ahtasyafi/Documents/programming/neo4j/gnn_env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py:424: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.\n",
      "  warnings.warn(\n",
      "/home/ahnaf-al-ghiffarri-ahtasyafi/Documents/programming/neo4j/gnn_env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py:1046: UserWarning: No positive class found in y_true, recall is set to one for all thresholds.\n",
      "  warnings.warn(\n",
      "/home/ahnaf-al-ghiffarri-ahtasyafi/Documents/programming/neo4j/gnn_env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py:424: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.\n",
      "  warnings.warn(\n",
      "/home/ahnaf-al-ghiffarri-ahtasyafi/Documents/programming/neo4j/gnn_env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py:1046: UserWarning: No positive class found in y_true, recall is set to one for all thresholds.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15 loss=0.0018 AUC=nan PR-AUC=0.0000\n",
      "Epoch 20 loss=0.0010 AUC=nan PR-AUC=0.0000\n",
      "Epoch 25 loss=0.0006 AUC=nan PR-AUC=0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ahnaf-al-ghiffarri-ahtasyafi/Documents/programming/neo4j/gnn_env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py:424: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.\n",
      "  warnings.warn(\n",
      "/home/ahnaf-al-ghiffarri-ahtasyafi/Documents/programming/neo4j/gnn_env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py:1046: UserWarning: No positive class found in y_true, recall is set to one for all thresholds.\n",
      "  warnings.warn(\n",
      "/home/ahnaf-al-ghiffarri-ahtasyafi/Documents/programming/neo4j/gnn_env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py:424: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.\n",
      "  warnings.warn(\n",
      "/home/ahnaf-al-ghiffarri-ahtasyafi/Documents/programming/neo4j/gnn_env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py:1046: UserWarning: No positive class found in y_true, recall is set to one for all thresholds.\n",
      "  warnings.warn(\n",
      "/home/ahnaf-al-ghiffarri-ahtasyafi/Documents/programming/neo4j/gnn_env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py:424: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.\n",
      "  warnings.warn(\n",
      "/home/ahnaf-al-ghiffarri-ahtasyafi/Documents/programming/neo4j/gnn_env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py:1046: UserWarning: No positive class found in y_true, recall is set to one for all thresholds.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30 loss=0.0004 AUC=nan PR-AUC=0.0000\n",
      "Epoch 35 loss=0.0003 AUC=nan PR-AUC=0.0000\n",
      "Epoch 40 loss=0.0004 AUC=nan PR-AUC=0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ahnaf-al-ghiffarri-ahtasyafi/Documents/programming/neo4j/gnn_env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py:424: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.\n",
      "  warnings.warn(\n",
      "/home/ahnaf-al-ghiffarri-ahtasyafi/Documents/programming/neo4j/gnn_env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py:1046: UserWarning: No positive class found in y_true, recall is set to one for all thresholds.\n",
      "  warnings.warn(\n",
      "/home/ahnaf-al-ghiffarri-ahtasyafi/Documents/programming/neo4j/gnn_env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py:424: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.\n",
      "  warnings.warn(\n",
      "/home/ahnaf-al-ghiffarri-ahtasyafi/Documents/programming/neo4j/gnn_env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py:1046: UserWarning: No positive class found in y_true, recall is set to one for all thresholds.\n",
      "  warnings.warn(\n",
      "/home/ahnaf-al-ghiffarri-ahtasyafi/Documents/programming/neo4j/gnn_env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py:424: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.\n",
      "  warnings.warn(\n",
      "/home/ahnaf-al-ghiffarri-ahtasyafi/Documents/programming/neo4j/gnn_env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py:1046: UserWarning: No positive class found in y_true, recall is set to one for all thresholds.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45 loss=0.0002 AUC=nan PR-AUC=0.0000\n",
      "Epoch 50 loss=0.0002 AUC=nan PR-AUC=0.0000\n",
      "Epoch 55 loss=0.0002 AUC=nan PR-AUC=0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ahnaf-al-ghiffarri-ahtasyafi/Documents/programming/neo4j/gnn_env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py:424: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.\n",
      "  warnings.warn(\n",
      "/home/ahnaf-al-ghiffarri-ahtasyafi/Documents/programming/neo4j/gnn_env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py:1046: UserWarning: No positive class found in y_true, recall is set to one for all thresholds.\n",
      "  warnings.warn(\n",
      "/home/ahnaf-al-ghiffarri-ahtasyafi/Documents/programming/neo4j/gnn_env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py:424: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.\n",
      "  warnings.warn(\n",
      "/home/ahnaf-al-ghiffarri-ahtasyafi/Documents/programming/neo4j/gnn_env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py:1046: UserWarning: No positive class found in y_true, recall is set to one for all thresholds.\n",
      "  warnings.warn(\n",
      "/home/ahnaf-al-ghiffarri-ahtasyafi/Documents/programming/neo4j/gnn_env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py:424: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.\n",
      "  warnings.warn(\n",
      "/home/ahnaf-al-ghiffarri-ahtasyafi/Documents/programming/neo4j/gnn_env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py:1046: UserWarning: No positive class found in y_true, recall is set to one for all thresholds.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 60 loss=0.0001 AUC=nan PR-AUC=0.0000\n",
      "Epoch 65 loss=0.0002 AUC=nan PR-AUC=0.0000\n",
      "Epoch 70 loss=0.0001 AUC=nan PR-AUC=0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ahnaf-al-ghiffarri-ahtasyafi/Documents/programming/neo4j/gnn_env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py:424: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.\n",
      "  warnings.warn(\n",
      "/home/ahnaf-al-ghiffarri-ahtasyafi/Documents/programming/neo4j/gnn_env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py:1046: UserWarning: No positive class found in y_true, recall is set to one for all thresholds.\n",
      "  warnings.warn(\n",
      "/home/ahnaf-al-ghiffarri-ahtasyafi/Documents/programming/neo4j/gnn_env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py:424: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.\n",
      "  warnings.warn(\n",
      "/home/ahnaf-al-ghiffarri-ahtasyafi/Documents/programming/neo4j/gnn_env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py:1046: UserWarning: No positive class found in y_true, recall is set to one for all thresholds.\n",
      "  warnings.warn(\n",
      "/home/ahnaf-al-ghiffarri-ahtasyafi/Documents/programming/neo4j/gnn_env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py:424: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.\n",
      "  warnings.warn(\n",
      "/home/ahnaf-al-ghiffarri-ahtasyafi/Documents/programming/neo4j/gnn_env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py:1046: UserWarning: No positive class found in y_true, recall is set to one for all thresholds.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 75 loss=0.0000 AUC=nan PR-AUC=0.0000\n",
      "Epoch 80 loss=0.0000 AUC=nan PR-AUC=0.0000\n",
      "Epoch 85 loss=0.0001 AUC=nan PR-AUC=0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ahnaf-al-ghiffarri-ahtasyafi/Documents/programming/neo4j/gnn_env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py:424: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.\n",
      "  warnings.warn(\n",
      "/home/ahnaf-al-ghiffarri-ahtasyafi/Documents/programming/neo4j/gnn_env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py:1046: UserWarning: No positive class found in y_true, recall is set to one for all thresholds.\n",
      "  warnings.warn(\n",
      "/home/ahnaf-al-ghiffarri-ahtasyafi/Documents/programming/neo4j/gnn_env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py:424: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.\n",
      "  warnings.warn(\n",
      "/home/ahnaf-al-ghiffarri-ahtasyafi/Documents/programming/neo4j/gnn_env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py:1046: UserWarning: No positive class found in y_true, recall is set to one for all thresholds.\n",
      "  warnings.warn(\n",
      "/home/ahnaf-al-ghiffarri-ahtasyafi/Documents/programming/neo4j/gnn_env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py:424: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.\n",
      "  warnings.warn(\n",
      "/home/ahnaf-al-ghiffarri-ahtasyafi/Documents/programming/neo4j/gnn_env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py:1046: UserWarning: No positive class found in y_true, recall is set to one for all thresholds.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 90 loss=0.0000 AUC=nan PR-AUC=0.0000\n",
      "Epoch 95 loss=0.0000 AUC=nan PR-AUC=0.0000\n",
      "Epoch 100 loss=0.0001 AUC=nan PR-AUC=0.0000\n",
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ahnaf-al-ghiffarri-ahtasyafi/Documents/programming/neo4j/gnn_env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py:424: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.\n",
      "  warnings.warn(\n",
      "/home/ahnaf-al-ghiffarri-ahtasyafi/Documents/programming/neo4j/gnn_env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py:1046: UserWarning: No positive class found in y_true, recall is set to one for all thresholds.\n",
      "  warnings.warn(\n",
      "/home/ahnaf-al-ghiffarri-ahtasyafi/Documents/programming/neo4j/gnn_env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py:424: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.\n",
      "  warnings.warn(\n",
      "/home/ahnaf-al-ghiffarri-ahtasyafi/Documents/programming/neo4j/gnn_env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py:1046: UserWarning: No positive class found in y_true, recall is set to one for all thresholds.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Cell 11 - train utilities\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = HybridGNN(in_dim=X.shape[1], hidden=128, out_dim=1, heads=4, dropout=0.3).to(device)\n",
    "data = data.to(device)\n",
    "\n",
    "# compute class weight\n",
    "pos_weight = max(1.0, float((~nodes['train_mask']).sum()) / max(1, nodes.loc[nodes['train_mask'],'is_fraud'].sum()))\n",
    "print(\"pos_weight:\", pos_weight)\n",
    "loss_fn = torch.nn.BCELoss()\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3, weight_decay=1e-5)\n",
    "best_auc = 0.0\n",
    "best_state = None\n",
    "patience = 20\n",
    "pat_step = 0\n",
    "\n",
    "for epoch in range(1,401):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    out = model(data.x, data.edge_index)\n",
    "    loss = loss_fn(out[data.train_mask], data.y[data.train_mask])\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if epoch % 5 == 0:\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            preds = out.cpu().numpy()\n",
    "            y_true = data.y.cpu().numpy()\n",
    "            test_idx = data.test_mask.cpu().numpy()\n",
    "            auc = roc_auc_score(y_true[test_idx], preds[test_idx])\n",
    "            pr = average_precision_score(y_true[test_idx], preds[test_idx])\n",
    "            print(f\"Epoch {epoch} loss={loss.item():.4f} AUC={auc:.4f} PR-AUC={pr:.4f}\")\n",
    "            if auc > best_auc + 1e-4:\n",
    "                best_auc = auc\n",
    "                best_state = model.state_dict()\n",
    "                pat_step = 0\n",
    "            else:\n",
    "                pat_step += 1\n",
    "        if pat_step >= patience:\n",
    "            print(\"Early stopping\")\n",
    "            break\n",
    "\n",
    "# load best\n",
    "if best_state is not None:\n",
    "    model.load_state_dict(best_state)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7ed2beb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ Evaluasi AUC dilewati: Data Test hanya memiliki 1 jenis label (misal 0 semua).\n",
      "   Score rata-rata prediksi: 0.00022658739\n",
      "ðŸ” Precision@k (Top 18 nodes): 0.0000\n",
      "------------------------------\n",
      "ðŸ’¾ File berhasil disimpan di:\n",
      "   /home/ahnaf-al-ghiffarri-ahtasyafi/Documents/programming/neo4j/gnn_model/output/gnn_hybrid_predicted_nodes.csv\n"
     ]
    }
   ],
   "source": [
    "# Cell 12 - evaluation & save (Modified Path)\n",
    "\n",
    "# 1. Lakukan Prediksi\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    # Ambil skor probabilitas (0.0 s/d 1.0)\n",
    "    scores = model(data.x, data.edge_index).cpu().numpy()\n",
    "\n",
    "nodes['fraud_score'] = scores\n",
    "\n",
    "# 2. Evaluasi (Hanya pada Test Set)\n",
    "y_true = nodes.loc[nodes['test_mask'], 'is_fraud'].values\n",
    "y_score = nodes.loc[nodes['test_mask'], 'fraud_score'].values\n",
    "\n",
    "# Cek apakah ada setidaknya 2 kelas (0 dan 1) di data test\n",
    "# (Mencegah error jika data dummy isinya 0 semua)\n",
    "if len(np.unique(y_true)) > 1:\n",
    "    auc = roc_auc_score(y_true, y_score)\n",
    "    pr = average_precision_score(y_true, y_score)\n",
    "    print(f\"âœ… Test AUC: {auc:.4f}\")\n",
    "    print(f\"âœ… PR-AUC : {pr:.4f}\")\n",
    "else:\n",
    "    print(\"âš ï¸ Evaluasi AUC dilewati: Data Test hanya memiliki 1 jenis label (misal 0 semua).\")\n",
    "    print(\"   Score rata-rata prediksi:\", np.mean(y_score))\n",
    "\n",
    "# 3. Precision @ K (Top 1% Suspects)\n",
    "k = max(1, int(0.01 * len(nodes)))  # Ambil top 1% atau minimal 1 node\n",
    "topk = nodes.sort_values('fraud_score', ascending=False).head(k)\n",
    "print(f\"ðŸ” Precision@k (Top {k} nodes): {topk['is_fraud'].mean():.4f}\")\n",
    "\n",
    "# 4. SAVE KE FOLDER KHUSUS (gnn_model/output/)\n",
    "# Kita gunakan \"../\" karena notebook ada di folder 'notebooks', jadi harus mundur satu level dulu\n",
    "SAVE_DIR = \"../gnn_model/output/\"\n",
    "os.makedirs(SAVE_DIR, exist_ok=True) # Buat folder otomatis jika belum ada\n",
    "\n",
    "filename = \"gnn_hybrid_predicted_nodes.csv\"\n",
    "save_path = os.path.join(SAVE_DIR, filename)\n",
    "\n",
    "# Simpan ID, Score, Label Asli, dan Fitur\n",
    "output_cols = ['node_id', 'mapped_id', 'fraud_score', 'is_fraud'] + FEATURE_COLS\n",
    "nodes[output_cols].to_csv(save_path, index=False)\n",
    "\n",
    "print(\"-\" * 30)\n",
    "print(f\"ðŸ’¾ File berhasil disimpan di:\\n   {os.path.abspath(save_path)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a8b3935e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“Š Laporan Pembagian Data:\n",
      "Total Data: 1879\n",
      "Data Train: 840 (Model belajar dari sini)\n",
      "Data Test : 360  (Model diuji di sini)\n",
      "\n",
      "âœ… Jadi, Train dan Test sudah ada, hanya saja mereka hidup dalam satu file/graph.\n"
     ]
    }
   ],
   "source": [
    "# Cek jumlah Train vs Test\n",
    "import pandas as pd\n",
    "\n",
    "# Load file prediksi yang baru saja kamu simpan\n",
    "df_pred = pd.read_csv(\"../gnn_model/output/gnn_hybrid_predicted_nodes.csv\")\n",
    "\n",
    "# Kita buka file config split yang tadi kita buat di Cell 5\n",
    "import json\n",
    "with open(\"../data/processed/split_config.json\", \"r\") as f:\n",
    "    split_info = json.load(f)\n",
    "\n",
    "print(\"ðŸ“Š Laporan Pembagian Data:\")\n",
    "print(f\"Total Data: {len(df_pred)}\")\n",
    "print(f\"Data Train: {split_info['train_count']} (Model belajar dari sini)\")\n",
    "print(f\"Data Test : {split_info['test_count']}  (Model diuji di sini)\")\n",
    "\n",
    "print(\"\\nâœ… Jadi, Train dan Test sudah ada, hanya saja mereka hidup dalam satu file/graph.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae6c656f",
   "metadata": {},
   "source": [
    "Injeksi fraud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "883df325",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ’‰ Memulai Injeksi Pola Fraud (Dengan Noise/Gangguan agar Realistis)...\n",
      "âœ… Injeksi Realistis Selesai.\n",
      "ðŸ“Š Total Fraud: 152\n",
      "--------------------\n",
      "fraud_reason\n",
      "Normal                             1727\n",
      "Upcoding (Tarif > 150% standar)     150\n",
      "Random Audit Discovery                2\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Cell 13 (REVISI - LEBIH REALISTIS) - Probabilistic Fraud Injection\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "print(\"ðŸ’‰ Memulai Injeksi Pola Fraud (Dengan Noise/Gangguan agar Realistis)...\")\n",
    "\n",
    "def inject_fraud_patterns_noisy(row):\n",
    "    # Kita gunakan Random Number (0.0 s/d 1.0) untuk probabilitas\n",
    "    prob = np.random.rand() \n",
    "    \n",
    "    label = 0\n",
    "    reason = \"Normal\"\n",
    "\n",
    "    # Skenario 1: Mark-up harga (TAPI tidak selalu fraud!)\n",
    "    # Hanya 80% dari kasus mark-up yang kita labeli fraud. Sisanya (20%) kita anggap legal.\n",
    "    if row['ratio_tarif'] > 1.5:\n",
    "        if prob < 0.80: # 80% chance fraud\n",
    "            label = 1\n",
    "            reason = \"Upcoding (Tarif > 150% standar)\"\n",
    "        else:\n",
    "            label = 0 # 20% kasus ini sebenarnya legal (misal dokter spesialis mahal)\n",
    "\n",
    "    # Skenario 2: Phantom Billing (Sangat mencurigakan, chance 95%)\n",
    "    elif row['lama_rawat'] == 0 and row['tarif_diklaim'] > 1000000:\n",
    "        if prob < 0.95:\n",
    "            label = 1\n",
    "            reason = \"Phantom Billing (Klaim besar tanpa rawat inap)\"\n",
    "\n",
    "    # Skenario 3: Kecurigaan GNN (Struktural)\n",
    "    # GNN curiga, tapi kita buat agak samar biar XGBoost gak cuma nyontek GNN\n",
    "    elif row['fraud_score'] > 0.9:\n",
    "        if prob < 0.70: # Cuma 70% valid, sisanya mungkin false alarm GNN\n",
    "            label = 1\n",
    "            reason = \"Structural Anomaly (Detected by GNN)\"\n",
    "            \n",
    "    # Skenario 4: Noise Murni (Kadang fraud terjadi tanpa pola jelas/Random)\n",
    "    # Kita acak 0.5% data jadi fraud tanpa alasan jelas (biar model pusing dikit)\n",
    "    elif prob < 0.005: \n",
    "        label = 1\n",
    "        reason = \"Random Audit Discovery\"\n",
    "\n",
    "    return pd.Series([label, reason])\n",
    "\n",
    "# Terapkan logika probabilistik ini\n",
    "nodes[['is_fraud', 'fraud_reason']] = nodes.apply(inject_fraud_patterns_noisy, axis=1)\n",
    "\n",
    "# Update Masking (Wajib dilakukan lagi karena label berubah)\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Cek apakah kita punya cukup fraud?\n",
    "if nodes['is_fraud'].sum() < 10:\n",
    "    print(\"âš ï¸ Fraud terlalu sedikit setelah noise, memaksa injeksi tambahan...\")\n",
    "    # Paksa beberapa node random jadi fraud\n",
    "    force_idx = np.random.choice(nodes.index, 20, replace=False)\n",
    "    nodes.loc[force_idx, 'is_fraud'] = 1\n",
    "    nodes.loc[force_idx, 'fraud_reason'] = \"Forced Sample\"\n",
    "\n",
    "# Split ulang index\n",
    "train_idx, test_idx = train_test_split(\n",
    "    nodes.index, \n",
    "    test_size=0.3, \n",
    "    stratify=nodes['is_fraud'], \n",
    "    random_state=SEED\n",
    ")\n",
    "\n",
    "# Reset kolom mask\n",
    "nodes['train_mask'] = False\n",
    "nodes['test_mask'] = False\n",
    "nodes.loc[train_idx, 'train_mask'] = True\n",
    "nodes.loc[test_idx, 'test_mask'] = True\n",
    "\n",
    "print(f\"âœ… Injeksi Realistis Selesai.\")\n",
    "print(f\"ðŸ“Š Total Fraud: {nodes['is_fraud'].sum()}\")\n",
    "print(\"-\" * 20)\n",
    "print(nodes['fraud_reason'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fd4c9774",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸš€ Melatih XGBoost dengan 74 fitur...\n",
      "------------------------------\n",
      "ðŸ† ENSEMBLE RESULT:\n",
      "âœ… Test AUC   : 0.9702 (Target > 0.97)\n",
      "âœ… Test PR-AUC: 0.6367\n"
     ]
    }
   ],
   "source": [
    "# Cell 14 - Train XGBoost Ensemble\n",
    "\n",
    "# 1. Definisikan Fitur untuk Ensemble\n",
    "# Kita gabungkan FEATURE_COLS (yang dipakai GNN) + 'fraud_score' (hasil GNN)\n",
    "# 'fraud_score' adalah fitur \"bocoran\" yang sangat kuat untuk XGBoost\n",
    "ensemble_feats = FEATURE_COLS + ['fraud_score'] \n",
    "\n",
    "print(f\"ðŸš€ Melatih XGBoost dengan {len(ensemble_feats)} fitur...\")\n",
    "\n",
    "# 2. Siapkan X (Fitur) dan y (Label) berdasarkan mask yang baru diupdate\n",
    "X_train = nodes.loc[nodes['train_mask'], ensemble_feats]\n",
    "y_train = nodes.loc[nodes['train_mask'], 'is_fraud']\n",
    "\n",
    "X_test = nodes.loc[nodes['test_mask'], ensemble_feats]\n",
    "y_test = nodes.loc[nodes['test_mask'], 'is_fraud']\n",
    "\n",
    "# 3. Training\n",
    "xgb_model = xgb.XGBClassifier(\n",
    "    n_estimators=200,\n",
    "    max_depth=6,\n",
    "    learning_rate=0.05,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    scale_pos_weight=3.0, # Memberi bobot lebih pada kelas Fraud (penting utk imbalance data)\n",
    "    random_state=SEED,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "xgb_model.fit(X_train, y_train)\n",
    "\n",
    "# 4. Evaluasi\n",
    "y_pred_prob = xgb_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "auc_xgb = roc_auc_score(y_test, y_pred_prob)\n",
    "pr_xgb = average_precision_score(y_test, y_pred_prob)\n",
    "\n",
    "print(\"-\" * 30)\n",
    "print(f\"ðŸ† ENSEMBLE RESULT:\")\n",
    "print(f\"âœ… Test AUC   : {auc_xgb:.4f} (Target > 0.97)\")\n",
    "print(f\"âœ… Test PR-AUC: {pr_xgb:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "41b54c98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ” Menghasilkan Penjelasan Detil untuk User...\n",
      "\n",
      "ðŸš¨ CONTOH LAPORAN AKHIR (TOP 5 SUSPECTS):\n",
      " mapped_id  tarif_diklaim  fraud_score  final_risk_score           ai_explanation\n",
      "      1156       181000.0          0.0          0.997487 Tarif Overpriced (+132%)\n",
      "       157       106000.0          0.0          0.996201 Tarif Overpriced (+114%)\n",
      "       484      4715000.0          0.0          0.996045  Tarif Overpriced (+80%)\n",
      "       359     14693000.0          0.0          0.995995 Tarif Overpriced (+161%)\n",
      "       801       517000.0          0.0          0.995961 Tarif Overpriced (+151%)\n"
     ]
    }
   ],
   "source": [
    "# Cell 15 - Generate Final Explanation (Reasoning)\n",
    "\n",
    "print(\"ðŸ” Menghasilkan Penjelasan Detil untuk User...\")\n",
    "\n",
    "# 1. Prediksi Risk Score Akhir ke SEMUA data\n",
    "# (Menggunakan model XGBoost yang baru dilatih)\n",
    "# Kita prediksi ulang semua baris untuk keperluan laporan lengkap\n",
    "nodes['final_risk_score'] = xgb_model.predict_proba(nodes[ensemble_feats])[:, 1]\n",
    "\n",
    "# 2. Fungsi Penjelasan (Explainable AI Logic)\n",
    "def generate_ai_explanation(row):\n",
    "    score = row['final_risk_score']\n",
    "    \n",
    "    # Jika score rendah (< 50%), anggap aman\n",
    "    if score < 0.5:\n",
    "        return \"Aman\"\n",
    "    \n",
    "    reasons = []\n",
    "    \n",
    "    # --- Cek Anomali Tabular (Data Klaim) ---\n",
    "    if row['ratio_tarif'] > 1.2:\n",
    "        # Tampilkan persentase mark-up\n",
    "        markup_pct = int((row['ratio_tarif'] - 1.0) * 100)\n",
    "        reasons.append(f\"Tarif Overpriced (+{markup_pct}%)\")\n",
    "        \n",
    "    if row['lama_rawat'] == 0 and row['tarif_diklaim'] > 1000000:\n",
    "        reasons.append(\"Tagihan Besar (0 Hari Rawat)\")\n",
    "        \n",
    "    # --- Cek Anomali Graph (Data Jejaring) ---\n",
    "    # Apakah dia berada di komunitas/kelompok yang banyak fraud-nya?\n",
    "    if row.get('community_train_fraud_rate', 0) > 0.3:\n",
    "        reasons.append(\"Lingkaran Komunitas High-Risk\")\n",
    "        \n",
    "    # Apakah GNN (Deep Learning) mencurigai struktur koneksinya?\n",
    "    if row['fraud_score'] > 0.75:\n",
    "        reasons.append(\"Pola Koneksi Mencurigakan (GNN)\")\n",
    "        \n",
    "    # --- Fallback ---\n",
    "    # Jika tidak ada rule spesifik yang kena tapi score tinggi (biasanya karena kombinasi fitur kompleks)\n",
    "    if len(reasons) == 0:\n",
    "        return \"High Risk (Anomaly Detected)\"\n",
    "        \n",
    "    return \" + \".join(reasons)\n",
    "\n",
    "# Terapkan ke nodes\n",
    "nodes['ai_explanation'] = nodes.apply(generate_ai_explanation, axis=1)\n",
    "\n",
    "# Tampilkan Contoh Hasil (Top 5 Paling Curang menurut Model)\n",
    "top_suspects = nodes.sort_values('final_risk_score', ascending=False).head(5)\n",
    "cols_view = ['mapped_id', 'tarif_diklaim', 'fraud_score', 'final_risk_score', 'ai_explanation']\n",
    "\n",
    "print(\"\\nðŸš¨ CONTOH LAPORAN AKHIR (TOP 5 SUSPECTS):\")\n",
    "print(top_suspects[cols_view].to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4d7a28d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ’¾ SUKSES! Pipeline Selesai.\n",
      "ðŸ“‚ File laporan akhir tersimpan di:\n",
      "   /home/ahnaf-al-ghiffarri-ahtasyafi/Documents/programming/neo4j/gnn_model/output/fraud_detection_final_report.csv\n",
      "----------------------------------------\n",
      "ðŸš€ Langkah Selanjutnya: Buka Grafana dan hubungkan file CSV ini sebagai Data Source.\n"
     ]
    }
   ],
   "source": [
    "# Cell 16 - Save Final Report\n",
    "\n",
    "# Tentukan nama file dan lokasi\n",
    "FINAL_FILENAME = \"fraud_detection_final_report.csv\"\n",
    "# Kita gunakan \"../\" karena posisi notebook ada di dalam folder 'notebooks'\n",
    "OUTPUT_PATH = os.path.join(\"../gnn_model/output/\", FINAL_FILENAME)\n",
    "\n",
    "# Pastikan folder output ada\n",
    "os.makedirs(os.path.dirname(OUTPUT_PATH), exist_ok=True)\n",
    "\n",
    "# Pilih kolom-kolom penting untuk dashboard\n",
    "save_cols = [\n",
    "    'node_id',           # ID Asli (misal: C-001)\n",
    "    'mapped_id',         # ID Internal Graph\n",
    "    'tarif_diklaim',     # Nominal (Rupiah)\n",
    "    'tarif_seharusnya',  # Standar (Rupiah)\n",
    "    'lama_rawat',        # Durasi (Hari)\n",
    "    'ratio_tarif',       # Rasio Markup\n",
    "    'fraud_score',       # Score GNN (0-1)\n",
    "    'final_risk_score',  # Score Akhir XGBoost (0-1)\n",
    "    'is_fraud',          # Label (0/1) - Hasil Injeksi/Ground Truth\n",
    "    'ai_explanation'     # Alasan Kenapa Fraud\n",
    "]\n",
    "\n",
    "# Simpan ke CSV\n",
    "nodes[save_cols].to_csv(OUTPUT_PATH, index=False)\n",
    "\n",
    "print(f\"ðŸ’¾ SUKSES! Pipeline Selesai.\")\n",
    "print(f\"ðŸ“‚ File laporan akhir tersimpan di:\\n   {os.path.abspath(OUTPUT_PATH)}\")\n",
    "print(\"-\" * 40)\n",
    "print(\"ðŸš€ Langkah Selanjutnya: Buka Grafana dan hubungkan file CSV ini sebagai Data Source.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gnn_env (3.10.19)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
